{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9f41dfc-3d1a-4999-9b39-432284d69c96",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94a64470-f744-4606-a478-28dee3b05738",
   "metadata": {},
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import schedule\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "from azure.storage.filedatalake import DataLakeServiceClient\n",
    "import logging\n",
    "\n",
    "##Configure logging to console and file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904bcf38-4530-4dff-a111-2024bb3d9a06",
   "metadata": {},
   "source": [
    "## Logging confg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c131f7-b81c-4693-b9df-6658819ec37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('pipeline.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483eacf6-54af-481e-98d6-39ee34479ae5",
   "metadata": {},
   "source": [
    "## Fetching Country Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7812dbe8-3a77-4da4-ac56-682c17d15486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "countries = ['india', 'us', 'uk', 'china', 'russia']\n",
    "base_url = 'https://restcountries.com/v3.1/name/'\n",
    "country_output_dir = 'country_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0c5505-c20a-4116-86b3-769c479f3144",
   "metadata": {},
   "source": [
    "## Database and ADLS info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8938a21c-8e5e-4518-931e-23a675d81067",
   "metadata": {},
   "source": [
    "\n",
    "sql_connection_string = \"Driver={SQL Server};Server=<server>;Database=<database>;Trusted_Connection=yes;\"\n",
    "adls_account_name = \"<csg10030000968d2b>\"\n",
    "adls_account_key = \"<sknAoR6qDF9LwJeaX+dEtxjQZN94fkz9BNMLI7/web3R2PwO2xEtA8txyMH5n49KYDBzZXVC9duTiL3M9Q++gplZ6KPxWZ2eqVDbN7KOw>\"\n",
    "adls_filesystem = \"data\"\n",
    "customer_table = \"CustomerTable\"\n",
    "product_table = \"ProductTable\"\n",
    "customer_output_path = \"customer_data\"\n",
    "product_output_path = \"product_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a78b79f-64e5-4464-bd7a-149ba9664b17",
   "metadata": {},
   "source": [
    "## Initialize ADLS client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c99f3ecc-9d9b-49f0-98af-d921bd1ca645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_adls_client():\n",
    "    try:\n",
    "        account_name = csg10030000968d2b\n",
    "        account_key = sknAoR6qDF9LwJeaX+dEtxjQZN94fkz9BNMLI7/web3R2PwO2xEtA8txyMH5n49KYDBzZXVC9duTiL3M9Q++gplZ6KPxWZ2eqVDbN7KOw\n",
    "\n",
    "        client = DataLakeServiceClient(\n",
    "            account_url=f\"https://{account_name1}.dfs.core.windows.net\",\n",
    "            credential=account_key\n",
    "        )\n",
    "        logger.info(\"Successfully initialized ADLS client\")\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error init.: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b113e06a-2bfd-404d-9508-7b5f1b1179f4",
   "metadata": {},
   "source": [
    " ## Fetch & Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8f981fd-c044-4304-9480-25f38b0859ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_country_data(country):\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}{country}\")\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        os.makedirs(country_output_dir, exist_ok=True)\n",
    "        filename = os.path.join(country_output_dir, f\"{country}.json\")\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "        logger.info(f\"The Data Is Saved Successfully For {country} To {filename}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Error in fetching data for {country}: {e}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"Error in decoding JSON for {country}: {e}\")\n",
    "    except IOError as e:\n",
    "        logger.error(f\"Error in writing file for {country}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f79202-e093-4210-918c-8f0e86d7e363",
   "metadata": {},
   "source": [
    "## Fetch customer count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63536134-9217-4bf1-beb9-05020f5403b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_customer_count():\n",
    "    try:\n",
    "        sql_connection_string = DefaultEndpoints Protocol=https:AccountName=csg10030000968d2b\n",
    "        conn = pyodbc.connect(sql_connection_string)\n",
    "        query = f\"SELECT COUNT(*) AS CustomerCount FROM {customer_table}\"\n",
    "        customer_count = pd.read_sql(query, conn).iloc[0][\"CustomerCount\"]\n",
    "        conn.close()\n",
    "        logger.info(f\"Customer count: {customer_count}\")\n",
    "        return customer_count\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in fetching customer count: {e}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f894623-daa6-437c-884f-2fc6c85760c7",
   "metadata": {},
   "source": [
    "## Copy to ADLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c36606f-3a8c-4f4a-b949-7275bbf37df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_to_adls(data, filesystem, directory, filename):\n",
    "    try:\n",
    "        adls_client = get_adls_client()\n",
    "        if adls_client is None:\n",
    "            logger.error(\"ADLS client Error...\")\n",
    "            return\n",
    "        file_system_client = adls_client.get_file_system_client(filesystem)\n",
    "        directory_client = file_system_client.get_directory_client(directory)\n",
    "        directory_client.create_directory()\n",
    "        file_client = directory_client.get_file_client(filename)\n",
    "        file_client.create_file()\n",
    "        file_client.append_data(data.to_parquet(), 0)\n",
    "        file_client.flush_data(len(data.to_parquet()))\n",
    "        logger.info(f\"Data copied : {directory}/{filename}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error copying to ADLS: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6dde2c-eab4-4e20-874a-0b3e7e38ce5e",
   "metadata": {},
   "source": [
    "## Parent pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12394e2d-66c2-4c24-832d-f6f2c077fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy customer data\n",
    "def copy_customer_data():\n",
    "    customer_count = get_customer_count()\n",
    "    if customer_count > 500:\n",
    "        try:\n",
    "            conn = pyodbc.connect(sql_connection_string)\n",
    "            query = f\"SELECT * FROM {customer_table}\"\n",
    "            customer_data = pd.read_sql(query, conn)\n",
    "            conn.close()\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "            filename = f\"customer_{timestamp}.parquet\"\n",
    "            copy_to_adls(customer_data, adls_filesystem, customer_output_path, filename)\n",
    "            logger.info(\"Customer data copied successfully\")\n",
    "            # Call child pipeline logic, passing customer count\n",
    "            copy_product_data(customer_count)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error copying customer data: {e}\")\n",
    "    else:\n",
    "        logger.info(f\"Customer count ({customer_count}) <= 500, skipping copy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2c6ac3-953e-4b62-ae65-bc508aa5639f",
   "metadata": {},
   "source": [
    "## Child pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc31f1ea-f547-4c7e-b6b9-da3ca4e923dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy product data\n",
    "def copy_product_data(customer_count):\n",
    "    if customer_count > 600:\n",
    "        try:\n",
    "            conn = pyodbc.connect(sql_connection_string)\n",
    "            query = f\"SELECT * FROM {product_table}\"\n",
    "            product_data = pd.read_sql(query, conn)\n",
    "            conn.close()\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "            filename = f\"product_{timestamp}.parquet\"\n",
    "            copy_to_adls(product_data, adls_filesystem, product_output_path, filename)\n",
    "            logger.info(\"Product data copied successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error copying product data: {e}\")\n",
    "    else:\n",
    "        logger.info(f\"Customer count ({customer_count}) <= 600, skipping product copy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfb2501-f456-4a98-8cc6-411b7aa0b19d",
   "metadata": {},
   "source": [
    "## Fetching & Copying data in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9546b4ae-bb31-492a-a6a4-d27e3ed184a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def job():\n",
    "    logger.info(\"Starting country data fetch\")\n",
    "    for country in countries:\n",
    "        fetch_country_data(country)\n",
    "    logger.info(\"Completed country data fetch\")\n",
    "    \n",
    "    logger.info(\"Starting database to ADLS copy\")\n",
    "    copy_customer_data()\n",
    "    logger.info(\"Completed database to ADLS copy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecda62d7-2b2a-44ee-ba40-121f1345613b",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba783c-1279-4bb3-828d-53c2ecf729db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        \n",
    "        logger.info(\"Output\")\n",
    "        job()\n",
    "        \n",
    "        # Format: 12:00 AM and 12:00 PM IST\n",
    "        ist = pytz.timezone('Asia/Kolkata')\n",
    "        schedule.every().day.at(\"00:00\").do(job).tag('data-job').timezone = ist\n",
    "        schedule.every().day.at(\"12:00\").do(job).tag('data-job').timezone = ist\n",
    "        logger.info(\"The Scheduler started. Waiting for scheduled times (12:00 AM and 12:00 PM IST)...\")\n",
    "        \n",
    "        while True:\n",
    "            schedule.run_pending()\n",
    "            time.sleep(60)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in main: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c947e-014b-4e16-8298-a28ad29c5dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
